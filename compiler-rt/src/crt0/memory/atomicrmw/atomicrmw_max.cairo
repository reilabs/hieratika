use crate::rtstate::RTState;
use crate::crt0::allocator::{AllocatorState, Address};
use crate::crt0::memory::{load::load, store::store};
use core::traits::{BitAnd, BitOr, BitXor};
use core::num::traits::{BitSize, Bounded, OverflowingMul, OverflowingSub};
use crate::integer::{u24::u24, u40::u40, u48::u48};
use crate::alu::smax::smax;

/// Atomically modify memory. Load a value from memory, compare it with the given value and
/// store the greater value into the memory. Signed comparison is performed. The value loaded from
/// the memory is returned. The number of loaded and stored bytes is equal to the size of T.
///
/// Since the Cairo VM is single-threaded, this operation does not need to be explicitly atomic.
/// The load-modify-store sequence cannot be interrupted.
///
/// This is the implementation of the `__llvm_atomicrmw_max_*` polyfills logic. It exists so that
/// it can be unit-tested with a mock allocator. The polyfills are wrappers over this function and
/// they get the actual allocator with the getter generated by Hieratika.
///
/// This is a generic implementation for every data type. Its specialized versions are defined in
/// this file.
pub fn atomicrmw_max<
    T,
    +Bounded<T>,
    +BitAnd<T>,
    +BitOr<T>,
    +BitSize<T>,
    +BitXor<T>,
    +Copy<T>,
    +Div<T>,
    +Drop<T>,
    +Into<u8, T>,
    +Into<T, u128>,
    +TryInto<u128, T>,
    +TryInto<T, u8>,
    +OverflowingMul<T>,
    +OverflowingSub<T>,
>(
    ref allocator: AllocatorState, address: Address, value: T,
) -> T {
    let old_value: T = load(ref allocator, address, 0);
    // smax returns the greater one of the input values. Since ALU polyfills operate exclusively on
    // u128, the input values must be casted into u128 first. Then, the result must be casted back
    // to T. Since T->u128 casting is safe, u128->T must be safe as well.
    let greater_value: T = smax::<T>(old_value.into(), value.into())
        .try_into()
        .expect('u128 from T, can\'t cast back');
    store(ref allocator, greater_value, address, 0);
    old_value
}

#[cfg(test)]
mod test {
    use super::*;
    use crate::crt0::allocator::{Allocator, AllocatorOps};
    use crate::integer::IntegerOps;
    use core::fmt::Debug;

    /// Prepare allocator for the test suite.
    ///
    /// Instantiate the allocator, allocate a memory region and store a predefined array of bytes
    /// at the beginning of the allocated region. The test cases will load bytes from that region.
    fn get_allocator() -> Box<AllocatorState> {
        let mut allocator = Allocator::new();
        let address1 = allocator.allocate(32);
        #[cairofmt::skip]
        let array1 = array![
            0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10,
        ];
        allocator.store(address1, @array1);

        BoxTrait::new(allocator)
    }

    /// The actual test case, generalized over the input data type.
    ///
    /// Perform the `atomicrmw max` operation on the first sizeof(T) bytes of the allocated memory
    /// region, using the given value.
    /// Check if the value stored in the memory at the end of the operation is equal to the provided
    /// value.
    fn test_atomicrmw_max<
        T,
        +Bounded<T>,
        +BitAnd<T>,
        +BitOr<T>,
        +BitSize<T>,
        +BitXor<T>,
        +Copy<T>,
        +Debug<T>,
        +Div<T>,
        +Drop<T>,
        +Into<u8, T>,
        +Into<T, u128>,
        +TryInto<u128, T>,
        +TryInto<T, u8>,
        +OverflowingMul<T>,
        +OverflowingSub<T>,
        +PartialEq<T>,
    >(
        value_greater_than_stored: T,
    ) {
        // Instantiate the allocator.
        let mut allocator = get_allocator().unbox();

        // We load from the address 0x00.
        let address = 0;
        let offset = 0;

        // Do the operation.
        let _old_value = atomicrmw_max::<T>(ref allocator, address, value_greater_than_stored);

        // Load the value from the same part of the memory and see if it was updated correctly.
        let new_value = load(ref allocator, address, offset);
        assert_eq!(new_value, value_greater_than_stored);
    }

    #[test]
    /// Test the `atomicrmw max` operation with u8 values.
    fn atomicrmw_max_u8() {
        test_atomicrmw_max::<u8>(0x7f);
    }

    #[test]
    /// Test the `atomicrmw max` operation with u16 values.
    fn atomicrmw_max_u16() {
        test_atomicrmw_max::<u16>(0x7fff);
    }

    #[test]
    /// Test the `atomicrmw max` operation with u24 values.
    fn atomicrmw_max_u24() {
        test_atomicrmw_max::<u24>(IntegerOps::new(0x7fffff));
    }

    #[test]
    /// Test the `atomicrmw max` operation with u32 values.
    fn atomicrmw_max_u32() {
        test_atomicrmw_max::<u32>(0x7fffffff);
    }

    #[test]
    /// Test the `atomicrmw max` operation with u40 values.
    fn atomicrmw_max_u40() {
        test_atomicrmw_max::<u40>(IntegerOps::new(0x7fffffffff));
    }

    #[test]
    /// Test the `atomicrmw max` operation with u48 values.
    fn atomicrmw_max_u48() {
        test_atomicrmw_max::<u48>(IntegerOps::new(0x7fffffffffff));
    }

    #[test]
    /// Test the `atomicrmw max` operation with u64 values.
    fn atomicrmw_max_u64() {
        test_atomicrmw_max::<u64>(0x7fffffffffffffff);
    }

    #[test]
    /// Test the `atomicrmw max` operation with u128 values.
    fn atomicrmw_max_u128() {
        test_atomicrmw_max::<u128>(0x7fffffffffffffffffffffffffffffff);
    }
}

pub fn __llvm_atomicrmw_max_p_b_b(ref state: RTState, address: Address, value: u8) -> u8 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_z_z(ref state: RTState, address: Address, value: u16) -> u16 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_x_x(ref state: RTState, address: Address, value: u24) -> u24 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_i_i(ref state: RTState, address: Address, value: u32) -> u32 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_n_n(ref state: RTState, address: Address, value: u40) -> u40 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_k_k(ref state: RTState, address: Address, value: u48) -> u48 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_l_l(ref state: RTState, address: Address, value: u64) -> u64 {
    atomicrmw_max(ref state.allocator, address, value)
}

pub fn __llvm_atomicrmw_max_p_o_o(ref state: RTState, address: Address, value: u128) -> u128 {
    atomicrmw_max(ref state.allocator, address, value)
}
